{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cd639c6",
   "metadata": {
    "id": "5cd639c6"
   },
   "source": [
    "\n",
    "# Seph's ModelV5 Development\n",
    "\n",
    "This notebook demonstrates the development of a custom neural network using TensorFlow and Keras, focusing on good coding practices and clear documentation.\n",
    "\n",
    "### Library Imports\n",
    "All necessary libraries are imported here for better organization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "nmovAo9dl9j9",
   "metadata": {
    "executionInfo": {
     "elapsed": 7227,
     "status": "ok",
     "timestamp": 1707024828340,
     "user": {
      "displayName": "Ant O. Greene",
      "userId": "00972082250917461325"
     },
     "user_tz": 300
    },
    "id": "nmovAo9dl9j9"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install tensorflow keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3979fb8e",
   "metadata": {
    "executionInfo": {
     "elapsed": 160,
     "status": "ok",
     "timestamp": 1707024831808,
     "user": {
      "displayName": "Ant O. Greene",
      "userId": "00972082250917461325"
     },
     "user_tz": 300
    },
    "id": "3979fb8e"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, optimizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opVa6LQrxyAb",
   "metadata": {
    "id": "opVa6LQrxyAb"
   },
   "source": [
    "## Synthetic Sensor data\n",
    "\n",
    "-------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "Kok9cB-CxAGS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 578
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 952,
     "status": "ok",
     "timestamp": 1707024839093,
     "user": {
      "displayName": "Ant O. Greene",
      "userId": "00972082250917461325"
     },
     "user_tz": 300
    },
    "id": "Kok9cB-CxAGS",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "b614a92f-4912-416d-d22d-7a4dc3e9d18e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-cdc35afc-a57a-4362-b0af-4260cf29f21d\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>action</th>\n",
       "      <th>reward</th>\n",
       "      <th>alpha</th>\n",
       "      <th>beta</th>\n",
       "      <th>delta</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>eta</th>\n",
       "      <th>gamma</th>\n",
       "      <th>iota</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor_126_diff</th>\n",
       "      <th>sensor_126_roll_avg</th>\n",
       "      <th>sensor_126_exp_mov_avg</th>\n",
       "      <th>sensor_126_lag_1</th>\n",
       "      <th>sensor_127_diff</th>\n",
       "      <th>sensor_127_roll_avg</th>\n",
       "      <th>sensor_127_exp_mov_avg</th>\n",
       "      <th>sensor_127_lag_1</th>\n",
       "      <th>sensor_mean</th>\n",
       "      <th>sensor_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-02-03 05:38:10</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.056821</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.816452</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.412571</td>\n",
       "      <td>0.403969</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.129797</td>\n",
       "      <td>-1.136164</td>\n",
       "      <td>-1.081711</td>\n",
       "      <td>-1.112852</td>\n",
       "      <td>0.056612</td>\n",
       "      <td>-0.142496</td>\n",
       "      <td>-0.188089</td>\n",
       "      <td>-0.102271</td>\n",
       "      <td>0.022779</td>\n",
       "      <td>1.014461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-02-03 05:27:37</td>\n",
       "      <td>3</td>\n",
       "      <td>0.907599</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.410918</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.813266</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.213815</td>\n",
       "      <td>-0.311204</td>\n",
       "      <td>-0.326941</td>\n",
       "      <td>-0.540476</td>\n",
       "      <td>0.034856</td>\n",
       "      <td>-0.084076</td>\n",
       "      <td>-0.031777</td>\n",
       "      <td>-0.079061</td>\n",
       "      <td>0.028387</td>\n",
       "      <td>1.018413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-02-03 05:27:32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.737502</td>\n",
       "      <td>0.393944</td>\n",
       "      <td>0.403244</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.256003</td>\n",
       "      <td>0.760693</td>\n",
       "      <td>0.716943</td>\n",
       "      <td>0.623687</td>\n",
       "      <td>-0.131104</td>\n",
       "      <td>0.271732</td>\n",
       "      <td>0.257087</td>\n",
       "      <td>0.135298</td>\n",
       "      <td>0.110811</td>\n",
       "      <td>1.035087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-02-03 05:31:55</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.842084</td>\n",
       "      <td>0.700677</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.713479</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064810</td>\n",
       "      <td>-0.403378</td>\n",
       "      <td>-0.375861</td>\n",
       "      <td>-0.376477</td>\n",
       "      <td>0.068926</td>\n",
       "      <td>0.808229</td>\n",
       "      <td>0.746149</td>\n",
       "      <td>0.876656</td>\n",
       "      <td>-0.011083</td>\n",
       "      <td>0.952480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-02-03 05:31:18</td>\n",
       "      <td>3</td>\n",
       "      <td>0.314379</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.752898</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.378943</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020419</td>\n",
       "      <td>-0.002146</td>\n",
       "      <td>-0.005821</td>\n",
       "      <td>-0.073236</td>\n",
       "      <td>0.085244</td>\n",
       "      <td>1.780611</td>\n",
       "      <td>1.713498</td>\n",
       "      <td>1.732328</td>\n",
       "      <td>-0.211948</td>\n",
       "      <td>1.004894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2024-02-03 05:34:10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.564325</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.884623</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265308</td>\n",
       "      <td>-1.300098</td>\n",
       "      <td>-1.239570</td>\n",
       "      <td>-1.132283</td>\n",
       "      <td>-0.103897</td>\n",
       "      <td>1.461013</td>\n",
       "      <td>1.397425</td>\n",
       "      <td>1.460604</td>\n",
       "      <td>-0.108008</td>\n",
       "      <td>1.031087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2024-02-03 05:33:05</td>\n",
       "      <td>3</td>\n",
       "      <td>0.789867</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.895359</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.445345</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.160482</td>\n",
       "      <td>0.771008</td>\n",
       "      <td>0.704103</td>\n",
       "      <td>0.513192</td>\n",
       "      <td>-0.169728</td>\n",
       "      <td>1.886030</td>\n",
       "      <td>1.800859</td>\n",
       "      <td>1.897871</td>\n",
       "      <td>-0.241431</td>\n",
       "      <td>1.007688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2024-02-03 05:40:16</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.434471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.128779</td>\n",
       "      <td>-1.323286</td>\n",
       "      <td>-1.277699</td>\n",
       "      <td>-1.497565</td>\n",
       "      <td>0.125176</td>\n",
       "      <td>-0.879830</td>\n",
       "      <td>-0.813615</td>\n",
       "      <td>-0.655383</td>\n",
       "      <td>0.078919</td>\n",
       "      <td>1.049465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2024-02-03 05:29:23</td>\n",
       "      <td>3</td>\n",
       "      <td>0.410669</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.855303</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.296650</td>\n",
       "      <td>0.301762</td>\n",
       "      <td>...</td>\n",
       "      <td>0.253545</td>\n",
       "      <td>-0.897371</td>\n",
       "      <td>-0.870099</td>\n",
       "      <td>-0.728895</td>\n",
       "      <td>0.088115</td>\n",
       "      <td>0.213095</td>\n",
       "      <td>0.241520</td>\n",
       "      <td>0.353181</td>\n",
       "      <td>-0.082863</td>\n",
       "      <td>1.051077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2024-02-03 05:33:31</td>\n",
       "      <td>3</td>\n",
       "      <td>0.561655</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.388413</td>\n",
       "      <td>0.825505</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.210295</td>\n",
       "      <td>0.017003</td>\n",
       "      <td>0.052767</td>\n",
       "      <td>0.323389</td>\n",
       "      <td>0.160286</td>\n",
       "      <td>-0.665811</td>\n",
       "      <td>-0.629482</td>\n",
       "      <td>-0.504049</td>\n",
       "      <td>-0.024341</td>\n",
       "      <td>1.035294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 527 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cdc35afc-a57a-4362-b0af-4260cf29f21d')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-cdc35afc-a57a-4362-b0af-4260cf29f21d button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-cdc35afc-a57a-4362-b0af-4260cf29f21d');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-0329eae6-c66b-48c9-a286-fee61bc536cd\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0329eae6-c66b-48c9-a286-fee61bc536cd')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-0329eae6-c66b-48c9-a286-fee61bc536cd button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "             timestamp  action    reward     alpha      beta     delta  \\\n",
       "0  2024-02-03 05:38:10       3 -0.056821  0.000000  0.000000  0.816452   \n",
       "1  2024-02-03 05:27:37       3  0.907599  0.000000  0.000000  0.410918   \n",
       "2  2024-02-03 05:27:32       3  0.737502  0.393944  0.403244  0.000000   \n",
       "3  2024-02-03 05:31:55       3 -0.842084  0.700677  0.000000  0.000000   \n",
       "4  2024-02-03 05:31:18       3  0.314379  0.000000  0.000000  0.752898   \n",
       "5  2024-02-03 05:34:10       3  0.564325  0.000000  0.000000  0.000000   \n",
       "6  2024-02-03 05:33:05       3  0.789867  0.000000  0.895359  0.000000   \n",
       "7  2024-02-03 05:40:16       3 -0.434471  0.000000  0.000000  0.000000   \n",
       "8  2024-02-03 05:29:23       3  0.410669  0.000000  0.000000  0.000000   \n",
       "9  2024-02-03 05:33:31       3  0.561655  0.000000  0.000000  0.000000   \n",
       "\n",
       "    epsilon       eta     gamma      iota  ...  sensor_126_diff  \\\n",
       "0  0.000000  0.412571  0.403969  0.000000  ...         0.129797   \n",
       "1  0.000000  0.000000  0.813266  0.000000  ...        -0.213815   \n",
       "2  0.000000  0.000000  0.000000  0.000000  ...        -0.256003   \n",
       "3  0.000000  0.000000  0.713479  0.000000  ...         0.064810   \n",
       "4  0.000000  0.000000  0.000000  0.378943  ...         0.020419   \n",
       "5  0.884623  0.000000  0.000000  0.000000  ...         0.265308   \n",
       "6  0.000000  0.000000  0.445345  0.000000  ...        -0.160482   \n",
       "7  0.000000  0.000000  0.000000  0.000000  ...        -0.128779   \n",
       "8  0.855303  0.000000  0.296650  0.301762  ...         0.253545   \n",
       "9  0.388413  0.825505  0.000000  0.000000  ...         0.210295   \n",
       "\n",
       "   sensor_126_roll_avg  sensor_126_exp_mov_avg  sensor_126_lag_1  \\\n",
       "0            -1.136164               -1.081711         -1.112852   \n",
       "1            -0.311204               -0.326941         -0.540476   \n",
       "2             0.760693                0.716943          0.623687   \n",
       "3            -0.403378               -0.375861         -0.376477   \n",
       "4            -0.002146               -0.005821         -0.073236   \n",
       "5            -1.300098               -1.239570         -1.132283   \n",
       "6             0.771008                0.704103          0.513192   \n",
       "7            -1.323286               -1.277699         -1.497565   \n",
       "8            -0.897371               -0.870099         -0.728895   \n",
       "9             0.017003                0.052767          0.323389   \n",
       "\n",
       "   sensor_127_diff  sensor_127_roll_avg  sensor_127_exp_mov_avg  \\\n",
       "0         0.056612            -0.142496               -0.188089   \n",
       "1         0.034856            -0.084076               -0.031777   \n",
       "2        -0.131104             0.271732                0.257087   \n",
       "3         0.068926             0.808229                0.746149   \n",
       "4         0.085244             1.780611                1.713498   \n",
       "5        -0.103897             1.461013                1.397425   \n",
       "6        -0.169728             1.886030                1.800859   \n",
       "7         0.125176            -0.879830               -0.813615   \n",
       "8         0.088115             0.213095                0.241520   \n",
       "9         0.160286            -0.665811               -0.629482   \n",
       "\n",
       "   sensor_127_lag_1  sensor_mean  sensor_std  \n",
       "0         -0.102271     0.022779    1.014461  \n",
       "1         -0.079061     0.028387    1.018413  \n",
       "2          0.135298     0.110811    1.035087  \n",
       "3          0.876656    -0.011083    0.952480  \n",
       "4          1.732328    -0.211948    1.004894  \n",
       "5          1.460604    -0.108008    1.031087  \n",
       "6          1.897871    -0.241431    1.007688  \n",
       "7         -0.655383     0.078919    1.049465  \n",
       "8          0.353181    -0.082863    1.051077  \n",
       "9         -0.504049    -0.024341    1.035294  \n",
       "\n",
       "[10 rows x 527 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/content/synthetic_datasetV2.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81124325",
   "metadata": {
    "id": "81124325"
   },
   "source": [
    "\n",
    "### Global Variables\n",
    "Defining any constants and global variables used throughout the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "743a72a4",
   "metadata": {
    "collapsed": true,
    "executionInfo": {
     "elapsed": 178,
     "status": "ok",
     "timestamp": 1707024845271,
     "user": {
      "displayName": "Ant O. Greene",
      "userId": "00972082250917461325"
     },
     "user_tz": 300
    },
    "id": "743a72a4",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Adjust these parameters as needed for your model\n",
    "seq_length = 128\n",
    "d_model = 512\n",
    "num_classes = 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68055aff",
   "metadata": {
    "id": "68055aff"
   },
   "source": [
    "\n",
    "## Custom Layer Definitions\n",
    "\n",
    "Here we define custom layers with appropriate documentation and naming conventions.\n",
    "\n",
    "### BoolformerLayer\n",
    "\n",
    "This custom TensorFlow layer performs a logical AND operation on its input and then processes it through a dense layer with ReLU activation. It has been enhanced with a trainable threshold and an attention mechanism. The inputs are transformed into boolean values based on the threshold, embedded, and processed through multi-head attention before being passed to a dense ReLU layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ecebd4a8",
   "metadata": {
    "collapsed": true,
    "executionInfo": {
     "elapsed": 187,
     "status": "ok",
     "timestamp": 1707024904319,
     "user": {
      "displayName": "Ant O. Greene",
      "userId": "00972082250917461325"
     },
     "user_tz": 300
    },
    "id": "ecebd4a8",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Custom Layer for Boolformer, with added trainable threshold and attention mechanism\n",
    "class BoolformerLayer(layers.Layer):\n",
    "    def __init__(self, embedding_dim=8, num_heads=2, threshold_init_value=0.5, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.threshold_init_value = threshold_init_value\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.threshold = self.add_weight(\n",
    "            name='threshold',\n",
    "            shape=(input_shape[-1],),\n",
    "            initializer=tf.constant_initializer(self.threshold_init_value),\n",
    "            trainable=True\n",
    "        )\n",
    "        self.embedding_layer = layers.Embedding(input_dim=2, output_dim=self.embedding_dim)\n",
    "        self.attention_layer = layers.MultiHeadAttention(num_heads=self.num_heads, key_dim=self.embedding_dim)\n",
    "        self.dense_layer = layers.Dense(input_shape[-1], activation='relu')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        boolean_inputs = tf.greater(inputs, self.threshold)\n",
    "        embeddings = self.embedding_layer(tf.cast(boolean_inputs, dtype=tf.int32))\n",
    "        attention_output = self.attention_layer(embeddings, embeddings)\n",
    "        attention_output_flat = tf.reshape(attention_output, [-1, attention_output.shape[1] * self.embedding_dim])\n",
    "        return self.dense_layer(attention_output_flat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d270c1e",
   "metadata": {
    "id": "3d270c1e"
   },
   "source": [
    "\n",
    "### QLearningLayer\n",
    "\n",
    "This layer is designed for reinforcement learning tasks, using a Q-learning algorithm to learn the quality of actions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d99d45e7",
   "metadata": {
    "collapsed": true,
    "executionInfo": {
     "elapsed": 160,
     "status": "ok",
     "timestamp": 1707024907449,
     "user": {
      "displayName": "Ant O. Greene",
      "userId": "00972082250917461325"
     },
     "user_tz": 300
    },
    "id": "d99d45e7",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class QLearningLayer(layers.Layer):\n",
    "    def __init__(self, action_space_size, learning_rate=0.01, gamma=0.95, **kwargs):\n",
    "        super(QLearningLayer, self).__init__(**kwargs)\n",
    "        self.action_space_size = action_space_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # A dense layer to process state and output Q-values for each action\n",
    "        self.dense = layers.Dense(self.action_space_size, activation=None)\n",
    "\n",
    "    def call(self, state, action=None, reward=None, next_state=None):\n",
    "        q_values = self.dense(state)\n",
    "\n",
    "        if action is not None and reward is not None and next_state is not None:\n",
    "            # Get the predicted Q-values for the next state\n",
    "            future_q_values = self.dense(next_state)\n",
    "            max_future_q = tf.reduce_max(future_q_values, axis=1)\n",
    "\n",
    "            # Compute the updated Q-value for the chosen action\n",
    "            q_update = reward + self.gamma * max_future_q\n",
    "            q_values_with_update = tf.tensor_scatter_nd_update(\n",
    "                q_values, tf.expand_dims(action, axis=-1), q_update)\n",
    "\n",
    "            # Update the Q-values\n",
    "            self.dense.set_weights([q_values_with_update])\n",
    "\n",
    "        return q_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41391791",
   "metadata": {
    "id": "41391791"
   },
   "source": [
    "\n",
    "## Helper Functions\n",
    "\n",
    "Defining helper functions such as positional encoding and transformer encoder with detailed comments for better understanding.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3709070",
   "metadata": {
    "id": "f3709070"
   },
   "source": [
    "\n",
    "### Positional Encoding Function\n",
    "\n",
    "Positional encoding adds information about the position of elements in the input sequence, crucial for models like transformers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0616acf",
   "metadata": {
    "collapsed": true,
    "executionInfo": {
     "elapsed": 169,
     "status": "ok",
     "timestamp": 1707024923784,
     "user": {
      "displayName": "Ant O. Greene",
      "userId": "00972082250917461325"
     },
     "user_tz": 300
    },
    "id": "f0616acf",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def positional_encoding(seq_length, d_model):\n",
    "    position = tf.range(seq_length, dtype=tf.float32)[:, tf.newaxis]\n",
    "    div_term = tf.exp(tf.range(0, d_model, 2, dtype=tf.float32) * -(tf.math.log(10000.0) / d_model))\n",
    "\n",
    "    # Creating sine and cosine functions separately and then concatenating them\n",
    "    sine_terms = tf.sin(position * div_term)\n",
    "    cosine_terms = tf.cos(position * div_term)\n",
    "\n",
    "    # Interleaving sine and cosine terms\n",
    "    pos_encoding = tf.reshape(tf.concat([sine_terms, cosine_terms], axis=-1), [1, seq_length, d_model])\n",
    "\n",
    "    return pos_encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1527ac5",
   "metadata": {
    "id": "a1527ac5"
   },
   "source": [
    "\n",
    "### Transformer Encoder Function\n",
    "\n",
    "The transformer encoder function applies transformations to the input data using layer normalization and multi-head attention, followed by a series of dense layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd3e2ba8",
   "metadata": {
    "collapsed": true,
    "executionInfo": {
     "elapsed": 193,
     "status": "ok",
     "timestamp": 1707024928359,
     "user": {
      "displayName": "Ant O. Greene",
      "userId": "00972082250917461325"
     },
     "user_tz": 300
    },
    "id": "fd3e2ba8",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = layers.MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(x, x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
    "    x = layers.Dense(ff_dim, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Dense(inputs.shape[-1])(x)\n",
    "    return x + res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4ed9bc",
   "metadata": {
    "id": "1f4ed9bc"
   },
   "source": [
    "\n",
    "## Model Building and Compilation\n",
    "\n",
    "Here we build and compile the neural network model, ensuring clarity and efficiency in the code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "MRB01YE-02bx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1315,
     "status": "ok",
     "timestamp": 1707028501962,
     "user": {
      "displayName": "Ant O. Greene",
      "userId": "00972082250917461325"
     },
     "user_tz": 300
    },
    "id": "MRB01YE-02bx",
    "outputId": "5cb316fa-284a-4735-ecc7-441ae8274bdd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_11 (InputLayer)       [(None, 128, 512)]           0         []                            \n",
      "                                                                                                  \n",
      " bidirectional_8 (Bidirecti  (None, 128, 256)             656384    ['input_11[0][0]']            \n",
      " onal)                                                                                            \n",
      "                                                                                                  \n",
      " conv1d_9 (Conv1D)           (None, 128, 32)              24608     ['bidirectional_8[0][0]']     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_19 (T  (None, 128, 32)              0         ['conv1d_9[0][0]']            \n",
      " FOpLambda)                                                                                       \n",
      "                                                                                                  \n",
      " multi_head_attention_5 (Mu  (None, 128, 32)              8416      ['tf.__operators__.add_19[0][0\n",
      " ltiHeadAttention)                                                  ]',                           \n",
      "                                                                     'tf.__operators__.add_19[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)        (None, 128, 32)              0         ['multi_head_attention_5[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_20 (T  (None, 128, 32)              0         ['tf.__operators__.add_19[0][0\n",
      " FOpLambda)                                                         ]',                           \n",
      "                                                                     'dropout_10[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_10 (La  (None, 128, 32)              64        ['tf.__operators__.add_20[0][0\n",
      " yerNormalization)                                                  ]']                           \n",
      "                                                                                                  \n",
      " dense_11 (Dense)            (None, 128, 64)              2112      ['layer_normalization_10[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dense_12 (Dense)            (None, 128, 32)              2080      ['dense_11[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)        (None, 128, 32)              0         ['dense_12[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_21 (T  (None, 128, 32)              0         ['layer_normalization_10[0][0]\n",
      " FOpLambda)                                                         ',                            \n",
      "                                                                     'dropout_11[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_11 (La  (None, 128, 32)              64        ['tf.__operators__.add_21[0][0\n",
      " yerNormalization)                                                  ]']                           \n",
      "                                                                                                  \n",
      " boolformer_layer_5 (Boolfo  (None, 32)                   33432     ['layer_normalization_11[0][0]\n",
      " rmerLayer)                                                         ']                            \n",
      "                                                                                                  \n",
      " q_learning_layer_5 (QLearn  (None,)                      330       ['boolformer_layer_5[0][0]']  \n",
      " ingLayer)                                                                                        \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 1)                    0         ['q_learning_layer_5[0][0]']  \n",
      "                                                                                                  \n",
      " Output (Dense)              (None, 10)                   20        ['flatten[0][0]']             \n",
      "                                                                                                  \n",
      " Reward (Dense)              (None, 1)                    2         ['flatten[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 727512 (2.78 MB)\n",
      "Trainable params: 727512 (2.78 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class BoolformerLayer(layers.Layer):\n",
    "    def __init__(self, embedding_dim=8, num_heads=2, threshold_init_value=0.5, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.threshold_init_value = threshold_init_value\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.threshold = self.add_weight(\n",
    "            name='threshold',\n",
    "            shape=(input_shape[-1],),\n",
    "            initializer=tf.constant_initializer(self.threshold_init_value),\n",
    "            trainable=True\n",
    "        )\n",
    "        self.embedding_layer = layers.Embedding(input_dim=2, output_dim=self.embedding_dim)\n",
    "        self.attention_layer = layers.MultiHeadAttention(num_heads=self.num_heads, key_dim=self.embedding_dim)\n",
    "        self.attention_norm_layer = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dense_layer = layers.Dense(input_shape[-1], activation='relu')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        boolean_inputs = tf.greater(inputs, self.threshold)\n",
    "        embeddings = self.embedding_layer(tf.cast(boolean_inputs, dtype=tf.int32))\n",
    "        attention_output = self.attention_layer(embeddings, embeddings)\n",
    "        attention_output_norm = self.attention_norm_layer(attention_output)\n",
    "        attention_output_flat = tf.reshape(attention_output_norm, shape=[-1, attention_output.shape[1] * self.embedding_dim])\n",
    "        return self.dense_layer(attention_output_flat)\n",
    "\n",
    "class QLearningLayer(layers.Layer):\n",
    "    def __init__(self, action_space_size, state_size, learning_rate=0.01, gamma=0.95, epsilon=0.1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.action_space_size = action_space_size\n",
    "        self.state_size = state_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.q_network = layers.Dense(self.action_space_size)\n",
    "\n",
    "    def call(self, state, action=None, reward=None, next_state=None):\n",
    "        q_values = self.q_network(state)\n",
    "\n",
    "        if action is not None and reward is not None and next_state is not None:\n",
    "            next_state_q_values = self.q_network(next_state)\n",
    "            target_q_value = reward + self.gamma * tf.reduce_max(next_state_q_values, axis=1)\n",
    "            mask = tf.one_hot(action, self.action_space_size)\n",
    "\n",
    "            with tf.GradientTape() as tape:\n",
    "                current_q_values = self.q_network(state)\n",
    "                q_action = tf.reduce_sum(tf.multiply(current_q_values, mask), axis=1)\n",
    "                loss = tf.reduce_mean(tf.square(target_q_value - q_action))\n",
    "\n",
    "            grads = tape.gradient(loss, self.q_network.trainable_variables)\n",
    "            self.q_network.optimizer.apply_gradients(zip(grads, self.q_network.trainable_variables))\n",
    "\n",
    "        action_probabilities = tf.nn.softmax(q_values, axis=1)\n",
    "        chosen_action = tf.cond(\n",
    "            tf.random.uniform([], 0, 1) < self.epsilon,\n",
    "            lambda: tf.random.uniform([tf.shape(state)[0]], 0, self.action_space_size, dtype=tf.int64),\n",
    "            lambda: tf.argmax(action_probabilities, axis=1)\n",
    "        )\n",
    "        return chosen_action\n",
    "\n",
    "def positional_encoding(seq_length, d_model):\n",
    "    position = tf.range(seq_length, dtype=tf.float32)[:, tf.newaxis]\n",
    "    div_term = tf.exp(tf.range(0, d_model // 2, dtype=tf.float32) * -(tf.math.log(10000.0) / d_model))\n",
    "    pos_encoding = position * div_term\n",
    "    sin_cos_encoding = tf.concat([tf.sin(pos_encoding), tf.cos(pos_encoding)], axis=-1)\n",
    "    return sin_cos_encoding[tf.newaxis, ...]\n",
    "\n",
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout_rate=0.1):\n",
    "    attention_output = layers.MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout_rate)(inputs, inputs)\n",
    "    attention_output = layers.Dropout(dropout_rate)(attention_output)\n",
    "    attention_output = layers.LayerNormalization(epsilon=1e-6)(inputs + attention_output)\n",
    "\n",
    "    ffn_output = layers.Dense(ff_dim, activation=\"relu\")(attention_output)\n",
    "    ffn_output = layers.Dense(inputs.shape[-1])(ffn_output)\n",
    "    ffn_output = layers.Dropout(dropout_rate)(ffn_output)\n",
    "    return layers.LayerNormalization(epsilon=1e-6)(attention_output + ffn_output)\n",
    "\n",
    "def create_neural_network_model(seq_length, d_model, num_classes):\n",
    "    input_layer = keras.Input(shape=(seq_length, d_model))\n",
    "\n",
    "    pos_encoding = positional_encoding(seq_length, 32)\n",
    "\n",
    "    x_lstm = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(input_layer)\n",
    "    x_conv = layers.Conv1D(filters=32, kernel_size=3, padding='same', activation='relu')(x_lstm)\n",
    "\n",
    "    x_pos_encoded = x_conv + pos_encoding\n",
    "\n",
    "    transformer_output = transformer_encoder(x_pos_encoded, head_size=32, num_heads=2, ff_dim=64)\n",
    "\n",
    "    state_size = transformer_output.shape[1] * transformer_output.shape[2]\n",
    "    x_bool = BoolformerLayer()(transformer_output)\n",
    "    rl_layer = QLearningLayer(action_space_size=num_classes, state_size=state_size)(x_bool)\n",
    "\n",
    "    # Flatten the output from QLearningLayer before final dense layers\n",
    "    reshaped_output = layers.Flatten()(rl_layer)\n",
    "\n",
    "    output_layer = layers.Dense(num_classes, activation='softmax', name='Output')(reshaped_output)\n",
    "    reward_layer = layers.Dense(1, name='Reward')(reshaped_output)\n",
    "\n",
    "    model = keras.Model(inputs=input_layer, outputs=[output_layer, reward_layer])\n",
    "\n",
    "    opt = optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=opt,\n",
    "                  loss={'Output': 'categorical_crossentropy', 'Reward': 'mean_squared_error'},\n",
    "                  metrics={'Output': 'accuracy'})\n",
    "\n",
    "    return model\n",
    "\n",
    "seq_length = 128\n",
    "d_model = 512\n",
    "num_classes = 10\n",
    "\n",
    "model = create_neural_network_model(seq_length, d_model, num_classes)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c24803f",
   "metadata": {
    "id": "9c24803f"
   },
   "source": [
    "\n",
    "## Hyperparameter Settings\n",
    "\n",
    "This section defines the hyperparameters for the model. Adjust these parameters to fine-tune the model's training process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "79a63da8",
   "metadata": {
    "collapsed": true,
    "executionInfo": {
     "elapsed": 181,
     "status": "ok",
     "timestamp": 1707028542754,
     "user": {
      "displayName": "Ant O. Greene",
      "userId": "00972082250917461325"
     },
     "user_tz": 300
    },
    "id": "79a63da8",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "learning_rate = 0.001\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "# Define additional hyperparameters here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a067f5",
   "metadata": {
    "id": "36a067f5"
   },
   "source": [
    "## Model Training\n",
    "\n",
    "In this section, we train the neural network model using the specified hyperparameters. The `model.fit()` function will be used to train the model with the training data. The validation data will be used to monitor the model's performance on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e171d91a",
   "metadata": {
    "collapsed": true,
    "id": "e171d91a",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Data Preparation\n",
    "# Auto-detecting output and reward columns based on model architecture\n",
    "output_label_column = df.columns[-2]  # Change this as per DataFrame Structure\n",
    "reward_label_column = df.columns[-1]  # Change this as per DataFrame Structure\n",
    "input_columns = df.drop([output_label_column, reward_label_column], axis=1)\n",
    "\n",
    "# Standardize the input features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(input_columns)\n",
    "\n",
    "# Preparing output and reward labels\n",
    "Y_output = df[output_label_column].values  # Assuming categorical labels\n",
    "Y_reward = df[reward_label_column].values  # Assuming continuous values\n",
    "\n",
    "# Splitting the dataset\n",
    "X_train, X_val, Y_output_train, Y_output_val, Y_reward_train, Y_reward_val = train_test_split(\n",
    "    X, Y_output, Y_reward, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Formatting data for model training\n",
    "train_data = (X_train, {'Output': Y_output_train, 'Reward': Y_reward_train})\n",
    "val_data = (X_val, {'Output': Y_output_val, 'Reward': Y_reward_val})\n",
    "\n",
    "# Model Training\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='min'),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, verbose=1, mode='min'),\n",
    "    ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=val_data,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# Model Saving\n",
    "model.save('SephsRL.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154263f6",
   "metadata": {
    "id": "154263f6"
   },
   "source": [
    "## Model Evaluation\n",
    "\n",
    "After training the model, it's important to evaluate its performance on a test dataset to understand its efficacy. The following code will use the `model.evaluate()` function to assess the model's accuracy and loss on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d01f4c",
   "metadata": {
    "collapsed": true,
    "id": "70d01f4c",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate the model on the test data\n",
    "# test_data = ...\n",
    "\n",
    "evaluation_metrics = model.evaluate(test_data)\n",
    "print(f\"Test Loss: {evaluation_metrics[0]}, Test Accuracy: {evaluation_metrics[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ca1a1f",
   "metadata": {
    "id": "f7ca1a1f"
   },
   "source": [
    "\n",
    "## Visualizing Model Performance\n",
    "\n",
    "Functions for plotting and analyzing the model's performance during training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d2c85c",
   "metadata": {
    "collapsed": true,
    "id": "65d2c85c",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to plot training history for both 'Output' and 'Reward' outputs, tailored to their characteristics\n",
    "def plot_custom_output_history(history):\n",
    "    num_plots = 2 + ('accuracy' in history.history)\n",
    "    fig, axes = plt.subplots(1, num_plots, figsize=(6 * num_plots, 5))\n",
    "\n",
    "    plot_index = 0\n",
    "\n",
    "    # Plotting accuracy for 'Output', if it's available\n",
    "    if 'accuracy' in history.history:\n",
    "        axes[plot_index].plot(history.history['accuracy'], label='Training Accuracy - Output')\n",
    "        axes[plot_index].plot(history.history['val_accuracy'], label='Validation Accuracy - Output')\n",
    "        axes[plot_index].set_title('Accuracy for Output')\n",
    "        axes[plot_index].set_xlabel('Epochs')\n",
    "        axes[plot_index].set_ylabel('Accuracy')\n",
    "        axes[plot_index].legend()\n",
    "        plot_index += 1\n",
    "\n",
    "    # Plotting loss for 'Output'\n",
    "    axes[plot_index].plot(history.history['Output_loss'], label='Training Loss - Output')\n",
    "    axes[plot_index].plot(history.history['val_Output_loss'], label='Validation Loss - Output')\n",
    "    axes[plot_index].set_title('Loss for Output')\n",
    "    axes[plot_index].set_xlabel('Epochs')\n",
    "    axes[plot_index].set_ylabel('Loss')\n",
    "    axes[plot_index].legend()\n",
    "    plot_index += 1\n",
    "\n",
    "    # Plotting loss for 'Reward'\n",
    "    axes[plot_index].plot(history.history['Reward_loss'], label='Training Loss - Reward')\n",
    "    axes[plot_index].plot(history.history['val_Reward_loss'], label='Validation Loss - Reward')\n",
    "    axes[plot_index].set_title('Loss for Reward')\n",
    "    axes[plot_index].set_xlabel('Epochs')\n",
    "    axes[plot_index].set_ylabel('Loss')\n",
    "    axes[plot_index].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call the function with the training history\n",
    "plot_custom_output_history(history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2d5ffc",
   "metadata": {
    "id": "eb2d5ffc"
   },
   "source": [
    "\n",
    "## Conclusion\n",
    "\n",
    "This notebook provided a detailed walkthrough for developing, training, and evaluating a neural network model with custom layers and advanced techniques, ensuring good coding practices and clear documentation throughout.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1RBpzHEPWeukCA0P8U554EmIc_WOkmvvr",
     "timestamp": 1707028603228
    },
    {
     "file_id": "1Zmtl1_3J275kf6wMjnDMNVfBnlwUjHpi",
     "timestamp": 1706659023772
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
